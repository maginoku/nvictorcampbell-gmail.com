{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import shutil\n",
    "import imgaug as aug\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mimg\n",
    "import imgaug.augmenters as iaa\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n",
    "\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "#print(os.listdir(\"../input\"))\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import gc\n",
    "import json\n",
    "\n",
    "#from fbprophet import Prophet\n",
    "from matplotlib import pyplot as plt\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random as rd # generating random numbers\n",
    "import datetime # manipulating date formats\n",
    "import matplotlib.pyplot as plt # basic plotting\n",
    "import seaborn as sns # for prettier plots\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    sales_train = pd.read_csv(r\"C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\sales_train.csv\")\n",
    "\n",
    "    item_categories = pd.read_csv(r\"C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\item_categories.csv\")\n",
    "\n",
    "    item = pd.read_csv(r\"C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\items.csv\")\n",
    "\n",
    "    shops = pd.read_csv(r\"C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\shops.csv\")\n",
    "\n",
    "    test = pd.read_csv(r\"C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\sales_test.csv\")\n",
    "    \n",
    "    sub = pd.read_csv(r\"C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\sample_submission.csv\")\n",
    "    \n",
    "    return sales_train, item_categories, item, shops, test, sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strptime() argument 1 must be str, not Timestamp",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-2fce42916127>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Here is where the formatting of the dates will be done correctly (Day - Month - Year)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%d.%m.%Y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Checking if it was done correctly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3848\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-2fce42916127>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Here is where the formatting of the dates will be done correctly (Day - Month - Year)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%d.%m.%Y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Checking if it was done correctly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: strptime() argument 1 must be str, not Timestamp"
     ]
    }
   ],
   "source": [
    "# Here is where the formatting of the dates will be done correctly (Day - Month - Year)\n",
    "sales.date=sales.date.apply(lambda x:datetime.datetime.strptime(x, '%d.%m.%Y'))\n",
    "\n",
    "# Checking if it was done correctly\n",
    "print(sales.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\items.csv\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\items.csv.zip\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\item_categories.csv\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\sales_test.csv\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\sales_train.csv\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\sales_train.csv.zip\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\sample_submission.csv\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\sample_submission.csv.zip\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\shops.csv\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Data sets\\test.csv.zip\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Preprocessing\\preprocessing.r\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Preprocessing\\Sales Reference.docx\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Preprocessing\\salesData.csv\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Python Files\\Machine Learning Sales Deep learning in TS.ipynb\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Python Files\\TS_ARIMA.ipynb\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Python Files\\Untitled.ipynb\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Python Files\\Untitled1.ipynb\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Python Files\\.ipynb_checkpoints\\Machine Learning Sales Deep learning in TS-checkpoint.ipynb\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Python Files\\.ipynb_checkpoints\\TS_ARIMA-checkpoint.ipynb\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Python Files\\.ipynb_checkpoints\\Untitled-checkpoint.ipynb\n",
      "C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project\\Python Files\\.ipynb_checkpoints\\Untitled1-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk(r'C:\\Users\\Nathan Campbell\\Documents\\Machine Leaning\\ML project'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, cats, items, shops, test, sample_submission = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  shop_id  item_id\n",
       "0   0        5     5037\n",
       "1   1        5     5320\n",
       "2   2        5     5233\n",
       "3   3        5     5232\n",
       "4   4        5     5268"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>02.01.2013</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03.01.2013</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.01.2013</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06.01.2013</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.01.2013</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  date_block_num  shop_id  item_id  item_price  \\\n",
       "date                                                                   \n",
       "02.01.2013  02.01.2013               0       59    22154      999.00   \n",
       "03.01.2013  03.01.2013               0       25     2552      899.00   \n",
       "05.01.2013  05.01.2013               0       25     2552      899.00   \n",
       "06.01.2013  06.01.2013               0       25     2554     1709.05   \n",
       "15.01.2013  15.01.2013               0       25     2555     1099.00   \n",
       "\n",
       "            item_cnt_day  \n",
       "date                      \n",
       "02.01.2013           1.0  \n",
       "03.01.2013           1.0  \n",
       "05.01.2013          -1.0  \n",
       "06.01.2013           1.0  \n",
       "15.01.2013           1.0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.set_index('date', drop=False, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set\n",
    "test['date_block_num'] = 34\n",
    "test['date_block_num'] = test['date_block_num'].astype(np.int8)\n",
    "test['shop_id'] = test['shop_id'].astype(np.int8)\n",
    "test['item_id'] = test['item_id'].astype(np.int16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stuff with price>10000 and sales>1001\n",
    "train = train[train.item_price<100000]\n",
    "train = train[train.item_cnt_day<1001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace one item with price below zero with median\n",
    "median = train[(train.shop_id==32)&(train.item_id==2973)&(train.date_block_num==4)&(train.item_price>0)].item_price.median()\n",
    "train.loc[train.item_price<0, 'item_price'] = median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix duplicate names\n",
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "\n",
    "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each shop_name starts with the city name, and each category contains type and subtype in itsname\n",
    "\n",
    "shops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\n",
    "shops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\n",
    "shops['city_code'] = LabelEncoder().fit_transform(shops['city'])\n",
    "shops = shops[['shop_id','city_code']]\n",
    "\n",
    "cats['split'] = cats['item_category_name'].str.split('-')\n",
    "cats['type'] = cats['split'].map(lambda x: x[0].strip())\n",
    "cats['type_code'] = LabelEncoder().fit_transform(cats['type'])\n",
    "# if subtype is nan then type\n",
    "cats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "cats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\n",
    "cats = cats[['item_category_id','type_code', 'subtype_code']]\n",
    "\n",
    "items.drop(['item_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate monthly sales and extend it with zero sales for each pair within the month\n",
    "\n",
    "from itertools import product\n",
    "matrix = []\n",
    "cols = ['date_block_num','shop_id','item_id']\n",
    "for i in range(34):\n",
    "    sales = train[train.date_block_num==i]\n",
    "    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\n",
    "    \n",
    "matrix = pd.DataFrame(np.vstack(matrix), columns=cols)\n",
    "matrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\n",
    "matrix['shop_id'] = matrix['shop_id'].astype(np.int8)\n",
    "matrix['item_id'] = matrix['item_id'].astype(np.int16)\n",
    "matrix.sort_values(cols,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add revenue column\n",
    "\n",
    "train['revenue'] = train['item_price'] *  train['item_cnt_day']\n",
    "\n",
    "#Add item_cnt_month columns\n",
    "\n",
    "group = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\n",
    "group.columns = ['item_cnt_month']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=cols, how='left')\n",
    "matrix['item_cnt_month'] = (matrix['item_cnt_month']\n",
    "                                .fillna(0)\n",
    "                                .clip(0,20) # NB clip target here\n",
    "                                .astype(np.float16))\n",
    "\n",
    "#Append features to test dataset\n",
    "\n",
    "test['date_block_num'] = 34\n",
    "test['date_block_num'] = test['date_block_num'].astype(np.int8)\n",
    "test['shop_id'] = test['shop_id'].astype(np.int8)\n",
    "test['item_id'] = test['item_id'].astype(np.int16)\n",
    "\n",
    "matrix = pd.concat([matrix, test], ignore_index=True, sort=False, keys=cols)\n",
    "matrix.fillna(0, inplace=True) # 34 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add shops, times, cats to matrix df\n",
    "\n",
    "matrix = pd.merge(matrix, shops, on=['shop_id'], how='left')\n",
    "matrix = pd.merge(matrix, items, on=['item_id'], how='left')\n",
    "matrix = pd.merge(matrix, cats, on=['item_category_id'], how='left')\n",
    "matrix['city_code'] = matrix['city_code'].astype(np.int8)\n",
    "matrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\n",
    "matrix['type_code'] = matrix['type_code'].astype(np.int8)\n",
    "matrix['subtype_code'] = matrix['subtype_code'].astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traget lags\n",
    "\n",
    "def lag_feature(df, lags, col):\n",
    "    tmp = df[['date_block_num','shop_id','item_id',col]]\n",
    "    for i in lags:\n",
    "        shifted = tmp.copy()\n",
    "        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n",
    "        shifted['date_block_num'] += i\n",
    "        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "    return df\n",
    "\n",
    "matrix = lag_feature(matrix, [1,2,3,6,12], 'item_cnt_month')\n",
    "\n",
    "#Mean encoded features\n",
    "\n",
    "group = matrix.groupby(['date_block_num']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num'], how='left')\n",
    "matrix['date_avg_item_cnt'] = matrix['date_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_avg_item_cnt')\n",
    "matrix.drop(['date_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_item_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\n",
    "matrix['date_item_avg_item_cnt'] = matrix['date_item_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1,2,3,6,12], 'date_item_avg_item_cnt')\n",
    "matrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_shop_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\n",
    "matrix['date_shop_avg_item_cnt'] = matrix['date_shop_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1,2,3,6,12], 'date_shop_avg_item_cnt')\n",
    "matrix.drop(['date_shop_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'item_category_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_cat_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_category_id'], how='left')\n",
    "matrix['date_cat_avg_item_cnt'] = matrix['date_cat_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_cat_avg_item_cnt')\n",
    "matrix.drop(['date_cat_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'shop_id', 'item_category_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_cat_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'item_category_id'], how='left')\n",
    "matrix['date_shop_cat_avg_item_cnt'] = matrix['date_shop_cat_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_shop_cat_avg_item_cnt')\n",
    "matrix.drop(['date_shop_cat_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'shop_id', 'type_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_type_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'type_code'], how='left')\n",
    "matrix['date_shop_type_avg_item_cnt'] = matrix['date_shop_type_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_shop_type_avg_item_cnt')\n",
    "matrix.drop(['date_shop_type_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_subtype_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\n",
    "matrix['date_shop_subtype_avg_item_cnt'] = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_shop_subtype_avg_item_cnt')\n",
    "matrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'city_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_city_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'city_code'], how='left')\n",
    "matrix['date_city_avg_item_cnt'] = matrix['date_city_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_city_avg_item_cnt')\n",
    "matrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'item_id', 'city_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_item_city_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'city_code'], how='left')\n",
    "matrix['date_item_city_avg_item_cnt'] = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_item_city_avg_item_cnt')\n",
    "matrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'type_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_type_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'type_code'], how='left')\n",
    "matrix['date_type_avg_item_cnt'] = matrix['date_type_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_type_avg_item_cnt')\n",
    "matrix.drop(['date_type_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_subtype_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'subtype_code'], how='left')\n",
    "matrix['date_subtype_avg_item_cnt'] = matrix['date_subtype_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_subtype_avg_item_cnt')\n",
    "matrix.drop(['date_subtype_avg_item_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix['month'] = matrix['date_block_num'] % 12\n",
    "days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "matrix['days'] = matrix['month'].map(days).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=items.groupby(['item_category_id']).count()\n",
    "x=x.sort_values(by='item_id',ascending=False)\n",
    "x=x.iloc[0:10].reset_index()\n",
    "x\n",
    "# #plot\n",
    "plt.figure(figsize=(8,4))\n",
    "ax= sns.barplot(x.item_category_id, x.item_id, alpha=0.8, palette ='coolwarm')\n",
    "plt.title(\"Items per Category\")\n",
    "plt.ylabel('# of items', fontsize=12)\n",
    "plt.xlabel('Category', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan Campbell\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['date_block_num', 'shop_id', 'item_id', 'item_cnt_month', 'ID',\n",
       "       'city_code', 'item_category_id', 'type_code', 'subtype_code',\n",
       "       'item_cnt_month_lag_1', 'item_cnt_month_lag_2', 'item_cnt_month_lag_3',\n",
       "       'item_cnt_month_lag_6', 'item_cnt_month_lag_12',\n",
       "       'date_avg_item_cnt_lag_1', 'date_item_avg_item_cnt_lag_1',\n",
       "       'date_item_avg_item_cnt_lag_2', 'date_item_avg_item_cnt_lag_3',\n",
       "       'date_item_avg_item_cnt_lag_6', 'date_item_avg_item_cnt_lag_12',\n",
       "       'date_shop_avg_item_cnt_lag_1', 'date_shop_avg_item_cnt_lag_2',\n",
       "       'date_shop_avg_item_cnt_lag_3', 'date_shop_avg_item_cnt_lag_6',\n",
       "       'date_shop_avg_item_cnt_lag_12', 'date_cat_avg_item_cnt_lag_1',\n",
       "       'date_shop_cat_avg_item_cnt_lag_1', 'date_shop_type_avg_item_cnt_lag_1',\n",
       "       'date_shop_subtype_avg_item_cnt_lag_1', 'date_city_avg_item_cnt_lag_1',\n",
       "       'date_item_city_avg_item_cnt_lag_1', 'date_type_avg_item_cnt_lag_1',\n",
       "       'date_subtype_avg_item_cnt_lag_1', 'item_avg_item_price_x',\n",
       "       'date_item_avg_item_price_x', 'date_item_avg_item_price_lag_1',\n",
       "       'date_item_avg_item_price_lag_2', 'date_item_avg_item_price_lag_3',\n",
       "       'date_item_avg_item_price_lag_4', 'date_item_avg_item_price_lag_5',\n",
       "       'date_item_avg_item_price_lag_6', 'delta_price_lag_1',\n",
       "       'delta_price_lag_2', 'delta_price_lag_3', 'delta_price_lag_4',\n",
       "       'delta_price_lag_5', 'delta_price_lag_6', 'item_avg_item_price_y',\n",
       "       'item_avg_item_price', 'date_item_avg_item_price_y', 'month', 'days',\n",
       "       'item_shop_last_sale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = matrix[matrix.date_block_num > 11]\n",
    "def fill_na(df):\n",
    "    for col in df.columns:\n",
    "        if ('_lag_' in col) & (df[col].isnull().any()):\n",
    "            if ('item_cnt' in col):\n",
    "                df[col].fillna(0, inplace=True)         \n",
    "    return df\n",
    "\n",
    "matrix = fill_na(matrix)\n",
    "matrix.to_pickle('data.pkl')\n",
    "matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-136f92aef52c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m data = data[[\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m'date_block_num'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;34m'shop_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;34m'item_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;31m# We want to silence any warnings about, e.g. moved modules.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;31m# e.g.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a = pd.read_pickle('data.pkl')\n",
    "data = data[[\n",
    "    'date_block_num',\n",
    "    'shop_id',\n",
    "    'item_id',\n",
    "    'item_cnt_month',\n",
    "    'city_code',\n",
    "    'item_category_id',\n",
    "    'type_code',\n",
    "    'subtype_code',\n",
    "    'item_cnt_month_lag_1',\n",
    "    'item_cnt_month_lag_2',\n",
    "    'item_cnt_month_lag_3',\n",
    "    'item_cnt_month_lag_6',\n",
    "    'item_cnt_month_lag_12',\n",
    "    'date_avg_item_cnt_lag_1',\n",
    "    'date_item_avg_item_cnt_lag_1',\n",
    "    'date_item_avg_item_cnt_lag_2',\n",
    "    'date_item_avg_item_cnt_lag_3',\n",
    "    'date_item_avg_item_cnt_lag_6',\n",
    "    'date_item_avg_item_cnt_lag_12',\n",
    "    'date_shop_avg_item_cnt_lag_1',\n",
    "    'date_shop_avg_item_cnt_lag_2',\n",
    "    'date_shop_avg_item_cnt_lag_3',\n",
    "    'date_shop_avg_item_cnt_lag_6',\n",
    "    'date_shop_avg_item_cnt_lag_12',\n",
    "    'date_cat_avg_item_cnt_lag_1',\n",
    "    'date_shop_cat_avg_item_cnt_lag_1',\n",
    "    #'date_shop_type_avg_item_cnt_lag_1',\n",
    "    #'date_shop_subtype_avg_item_cnt_lag_1',\n",
    "    'date_city_avg_item_cnt_lag_1',\n",
    "    'date_item_city_avg_item_cnt_lag_1',\n",
    "    #'date_type_avg_item_cnt_lag_1',\n",
    "    #'date_subtype_avg_item_cnt_lag_1',\n",
    "    #'delta_price_lag',\n",
    "    'month',\n",
    "    'days',\n",
    "    'item_shop_last_sale',\n",
    "    #'item_last_sale',\n",
    "    #'item_shop_first_sale',\n",
    "    #'item_first_sale',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n",
    "Y_train = data[data.date_block_num < 33]['item_cnt_month']\n",
    "X_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n",
    "Y_valid = data[data.date_block_num == 33]['item_cnt_month']\n",
    "X_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LTSM\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred -y_true), axis=-1))\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(15, input_shape=(1,34)))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(loss='mean_squared_error', optimizer='adam',  metrics=[rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data between -1 and 1 and to 3D\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "x_train_scaled = scaler.fit_transform(X_train)\n",
    "x_valid_scaled = scaler.fit_transform(X_valid)\n",
    "x_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 1\n",
    "\n",
    "x_train_reshaped = x_train_scaled.reshape((x_train_scaled.shape[0], 1, x_train_scaled.shape[1]))\n",
    "x_val_resaped = x_valid_scaled.reshape((x_valid_scaled.shape[0], 1, x_valid_scaled.shape[1]))\n",
    "x_test_resaped = x_test_scaled.reshape((x_test_scaled.shape[0], 1, x_test_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_4_input to have shape (1, 34) but got array with shape (1, 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-e2aa30821326>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_reshaped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val_resaped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_pre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val_resaped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_4_input to have shape (1, 34) but got array with shape (1, 26)"
     ]
    }
   ],
   "source": [
    "history = model_lstm.fit(x_train_reshaped, Y_train, validation_data=(x_val_resaped, Y_valid),epochs=10, batch_size=512, verbose=2, shuffle=False)\n",
    "y_pre = model_lstm.predict(x_val_resaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_3_input to have shape (1, 34) but got array with shape (1, 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-f6666fe41780>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_resaped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m submission = pd.DataFrame({\n\u001b[0;32m      4\u001b[0m     \u001b[1;34m\"ID\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;34m\"item_cnt_month\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_3_input to have shape (1, 34) but got array with shape (1, 30)"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "Y_test = model_lstm.predict(x_test_resaped).clip(0, 20)\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test.index, \n",
    "    \"item_cnt_month\": Y_test.flatten()\n",
    "})\n",
    "submission.to_csv('lstm_submission.csv', index=False)\n",
    "pickle.dump(Y_test, open('lstm_test.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
